{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport math\nfrom typing import List, Tuple, Dict\nfrom collections import defaultdict\n\nclass BeliefMeasurementPipeline:\n    \"\"\"\n    A pipeline to measure belief alignment between a proposition and free-form text.\n    Returns a score in [0,1] where 0=strongly disagrees, 0.5=neutral, 1=strongly agrees.\n    \"\"\"\n    \n    def __init__(self):\n        # Agreement indicators with weights\n        self.agreement_markers = {\n            'strong_agree': {\n                'patterns': [r'\\b(absolutely|completely|totally|entirely|fully)\\s+(agree|support|believe|endorse)',\n                           r'\\b(strongly|firmly)\\s+(agree|support|believe|endorse)',\n                           r'\\b(without\\s+doubt|undoubtedly|certainly|definitely)\\b.*\\b(true|correct|right)\\b',\n                           r'\\bI\\s+(completely|totally|absolutely|strongly)\\s+(agree|support|believe)\\b'],\n                'weight': 0.9\n            },\n            'agree': {\n                'patterns': [r'\\b(agree|support|believe|endorse|accept|embrace)\\b',\n                           r'\\b(yes|correct|true|right|accurate|valid)\\b',\n                           r'\\bI\\s+(think|believe|feel)\\s+.*\\b(true|correct|right)\\b'],\n                'weight': 0.7\n            },\n            'weak_agree': {\n                'patterns': [r'\\b(somewhat|partially|largely|mostly|generally)\\s+(agree|support|believe)',\n                           r'\\b(tend\\s+to|inclined\\s+to)\\s+(agree|believe|support)',\n                           r'\\b(probably|likely)\\s+(true|correct|right)\\b'],\n                'weight': 0.6\n            }\n        }\n        \n        # Disagreement indicators\n        self.disagreement_markers = {\n            'strong_disagree': {\n                'patterns': [r'\\b(absolutely|completely|totally|entirely|strongly)\\s+(disagree|oppose|reject)',\n                           r'\\b(never|not\\s+at\\s+all|in\\s+no\\s+way)\\b',\n                           r'\\b(completely|utterly|totally)\\s+(false|wrong|incorrect)',\n                           r'\\bI\\s+(completely|totally|absolutely|strongly)\\s+(disagree|oppose|reject)\\b'],\n                'weight': 0.1\n            },\n            'disagree': {\n                'patterns': [r'\\b(disagree|oppose|reject|deny|refute|dispute)\\b',\n                           r'\\b(no|false|wrong|incorrect|invalid|untrue)\\b',\n                           r'\\bI\\s+(don\\'?t|do\\s+not)\\s+(agree|believe|support|think)\\b'],\n                'weight': 0.3\n            },\n            'weak_disagree': {\n                'patterns': [r'\\b(somewhat|partially)\\s+(disagree|oppose)',\n                           r'\\b(doubt|question|skeptical|uncertain)\\b',\n                           r'\\b(probably|likely)\\s+(false|wrong|incorrect)\\b'],\n                'weight': 0.4\n            }\n        }\n        \n        # Neutral indicators\n        self.neutral_markers = {\n            'patterns': [r'\\b(neutral|undecided|unsure|uncertain|mixed\\s+feelings)\\b',\n                        r'\\b(both\\s+sides|on\\s+one\\s+hand.*on\\s+the\\s+other)\\b',\n                        r'\\b(depends|it\\'?s\\s+complicated|not\\s+sure)\\b'],\n            'weight': 0.5\n        }\n        \n    def handle_negations(self, text: str) -> str:\n        \"\"\"Handle negations that might flip the meaning.\"\"\"\n        # Simple negation patterns\n        negation_patterns = [\n            (r'\\b(do\\s+not|don\\'t|does\\s+not|doesn\\'t|did\\s+not|didn\\'t)\\s+', ''),\n            (r'\\b(not|never|no)\\s+', ''),\n            (r'\\b(isn\\'t|aren\\'t|wasn\\'t|weren\\'t|won\\'t|wouldn\\'t|can\\'t|couldn\\'t)\\b', ''),\n        ]\n        \n        negation_count = 0\n        processed_text = text.lower()\n        \n        for pattern, replacement in negation_patterns:\n            matches = re.findall(pattern, processed_text, re.IGNORECASE)\n            negation_count += len(matches)\n            processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)\n        \n        return processed_text, negation_count % 2 == 1  # Odd number of negations = flipped\n\n    def extract_agreement_signals(self, text: str, proposition: str) -> Dict[str, float]:\n        \"\"\"Extract agreement/disagreement signals from text.\"\"\"\n        text_lower = text.lower()\n        prop_lower = proposition.lower()\n        \n        # Handle negations\n        processed_text, is_negated = self.handle_negations(text)\n        \n        # Combine text and proposition for context-aware matching\n        combined_text = f\"{prop_lower} {processed_text}\"\n        \n        signals = defaultdict(list)\n        \n        # Check agreement markers\n        for level, markers in self.agreement_markers.items():\n            for pattern in markers['patterns']:\n                matches = re.findall(pattern, combined_text, re.IGNORECASE)\n                if matches:\n                    weight = markers['weight']\n                    if is_negated:\n                        weight = 1.0 - weight  # Flip due to negation\n                    signals['agreement'].extend([weight] * len(matches))\n        \n        # Check disagreement markers\n        for level, markers in self.disagreement_markers.items():\n            for pattern in markers['patterns']:\n                matches = re.findall(pattern, combined_text, re.IGNORECASE)\n                if matches:\n                    weight = markers['weight']\n                    if is_negated:\n                        weight = 1.0 - weight  # Flip due to negation\n                    signals['disagreement'].extend([weight] * len(matches))\n        \n        # Check neutral markers\n        for pattern in self.neutral_markers['patterns']:\n            matches = re.findall(pattern, combined_text, re.IGNORECASE)\n            if matches:\n                signals['neutral'].extend([self.neutral_markers['weight']] * len(matches))\n        \n        return dict(signals)\n    \n    def calculate_semantic_similarity(self, text: str, proposition: str) -> float:\n        \"\"\"\n        Simple semantic similarity based on word overlap and key terms.\n        In a production system, this would use embeddings.\n        \"\"\"\n        # Tokenize and clean\n        def tokenize(s):\n            return set(re.findall(r'\\b\\w+\\b', s.lower()))\n        \n        text_tokens = tokenize(text)\n        prop_tokens = tokenize(proposition)\n        \n        if not prop_tokens:\n            return 0.5\n        \n        # Calculate overlap\n        intersection = text_tokens.intersection(prop_tokens)\n        union = text_tokens.union(prop_tokens)\n        \n        if not union:\n            return 0.5\n        \n        jaccard_similarity = len(intersection) / len(union)\n        \n        # Boost for exact proposition mentions\n        prop_words = proposition.lower().split()\n        text_lower = text.lower()\n        \n        exact_mentions = sum(1 for word in prop_words if word in text_lower)\n        mention_boost = min(exact_mentions / len(prop_words), 0.3)\n        \n        return min(jaccard_similarity + mention_boost, 1.0)\n    \n    def analyze_context_sentiment(self, text: str, proposition: str) -> float:\n        \"\"\"\n        Analyze sentiment in context of the proposition.\n        Simple implementation - in production would use proper sentiment analysis.\n        \"\"\"\n        text_lower = text.lower()\n        \n        # Positive sentiment words\n        positive_words = ['good', 'great', 'excellent', 'wonderful', 'amazing', 'fantastic',\n                         'beneficial', 'helpful', 'valuable', 'important', 'necessary',\n                         'essential', 'vital', 'crucial', 'significant']\n        \n        # Negative sentiment words\n        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'wrong', 'harmful',\n                         'dangerous', 'problematic', 'concerning', 'worrying', 'alarming',\n                         'unnecessary', 'useless', 'pointless', 'wasteful']\n        \n        positive_count = sum(1 for word in positive_words if word in text_lower)\n        negative_count = sum(1 for word in negative_words if word in text_lower)\n        \n        if positive_count == 0 and negative_count == 0:\n            return 0.5\n        \n        total = positive_count + negative_count\n        return positive_count / total\n    \n    def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n        \"\"\"\n        Main method to measure belief alignment.\n        Returns belief score and detailed breakdown.\n        \"\"\"\n        if not proposition.strip() or not text.strip():\n            return 0.5, {'error': 'Empty proposition or text'}\n        \n        # Extract signals\n        signals = self.extract_agreement_signals(text, proposition)\n        \n        # Calculate components\n        semantic_sim = self.calculate_semantic_similarity(text, proposition)\n        context_sentiment = self.analyze_context_sentiment(text, proposition)\n        \n        # Aggregate agreement/disagreement signals\n        agreement_scores = signals.get('agreement', [])\n        disagreement_scores = signals.get('disagreement', [])\n        neutral_scores = signals.get('neutral', [])\n        \n        # Calculate weighted averages\n        if agreement_scores:\n            avg_agreement = sum(agreement_scores) / len(agreement_scores)\n        else:\n            avg_agreement = None\n            \n        if disagreement_scores:\n            avg_disagreement = sum(disagreement_scores) / len(disagreement_scores)\n        else:\n            avg_disagreement = None\n        \n        # Combine signals with weights\n        components = []\n        weights = []\n        \n        # Primary signals (explicit agreement/disagreement)\n        if avg_agreement is not None:\n            components.append(avg_agreement)\n            weights.append(0.5)  # High weight for explicit agreement\n        \n        if avg_disagreement is not None:\n            components.append(avg_disagreement)\n            weights.append(0.5)  # High weight for explicit disagreement\n        \n        # Secondary signals\n        if semantic_sim > 0:\n            components.append(0.5 + (semantic_sim - 0.5) * 0.3)  # Moderate influence\n            weights.append(0.2)\n        \n        if context_sentiment != 0.5:\n            components.append(context_sentiment)\n            weights.append(0.2)\n        \n        # Handle neutral signals\n        if neutral_scores:\n            components.append(0.5)\n            weights.append(0.3)\n        \n        # Default to neutral if no signals\n        if not components:\n            final_score = 0.5\n        else:\n            # Weighted average\n            final_score = sum(c * w for c, w in zip(components, weights)) / sum(weights)\n        \n        # Ensure score is in [0, 1]\n        final_score = max(0.0, min(1.0, final_score))\n        \n        # Prepare detailed breakdown\n        breakdown = {\n            'final_score': final_score,\n            'semantic_similarity': semantic_sim,\n            'context_sentiment': context_sentiment,\n            'agreement_signals': len(agreement_scores),\n            'disagreement_signals': len(disagreement_scores),\n            'neutral_signals': len(neutral_scores),\n            'avg_agreement': avg_agreement,\n            'avg_disagreement': avg_disagreement,\n            'components_used': len(components)\n        }\n        \n        return final_score, breakdown\n\n\n# Test the pipeline with diverse cases\ndef test_pipeline():\n    pipeline = BeliefMeasurementPipeline()\n    \n    test_cases = [\n        {\n            'proposition': 'Climate change is a serious threat',\n            'text': 'I absolutely agree that climate change poses a significant danger to our planet.',\n            'expected_range': (0.8, 1.0)\n        },\n        {\n            'proposition': 'Climate change is a serious threat',\n            'text': 'Climate change is completely overblown and not a real problem at all.',\n            'expected_range': (0.0, 0.3)\n        },\n        {\n            'proposition': 'Exercise is beneficial for health',\n            'text': 'I think exercise can be helpful but it depends on the person and situation.',\n            'expected_range': (0.5, 0.7)\n        },\n        {\n            'proposition': 'Cats are better than dogs',\n            'text': 'I love both cats and dogs equally. Both make wonderful pets.',\n            'expected_range': (0.4, 0.6)\n        },\n        {\n            'proposition': 'Remote work increases productivity',\n            'text': 'In my experience, working from home has made me much more efficient and productive.',\n            'expected_range': (0.7, 0.9)\n        }\n    ]\n    \n    print(\"Testing Belief Measurement Pipeline\")\n    print(\"=\" * 50)\n    \n    for i, case in enumerate(test_cases, 1):\n        score, breakdown = pipeline.measure_belief(case['proposition'], case['text'])\n        \n        print(f\"\\nTest Case {i}:\")\n        print(f\"Proposition: {case['proposition']}\")\n        print(f\"Text: {case['text']}\")\n        print(f\"Score: {score:.3f}\")\n        print(f\"Expected Range: {case['expected_range']}\")\n        \n        # Check if score is in expected range\n        in_range = case['expected_range'][0] <= score <= case['expected_range'][1]\n        print(f\"✓ In Expected Range: {in_range}\")\n        \n        print(f\"Breakdown: {breakdown}\")\n        print(\"-\" * 30)\n\n# Additional test cases for more comprehensive evaluation\ndef extended_test():\n    pipeline = BeliefMeasurementPipeline()\n    \n    extended_cases = [\n        {\n            'name': 'Strong Agreement with Reasoning',\n            'proposition': 'Education is important for society',\n            'text': 'I firmly believe education is crucial. It empowers individuals, drives innovation, and creates a more informed citizenry.',\n            'expected_range': (0.8, 1.0)\n        },\n        {\n            'name': 'Subtle Disagreement',\n            'proposition': 'Social media is beneficial for mental health',\n            'text': 'While social media connects people, I question whether it truly helps mental health. Studies suggest it might actually increase anxiety.',\n            'expected_range': (0.2, 0.5)\n        },\n        {\n            'name': 'Neutral with Complexity',\n            'proposition': 'Artificial intelligence will replace most jobs',\n            'text': 'AI will certainly change the job market. Some roles will disappear, others will emerge. The net effect is hard to predict.',\n            'expected_range': (0.4, 0.6)\n        },\n        {\n            'name': 'Strong Disagreement',\n            'proposition': 'Vaccines are dangerous',\n            'text': 'I completely disagree. Vaccines are safe and effective. This claim is utterly false and contradicts scientific evidence.',\n            'expected_range': (0.0, 0.2)\n        },\n        {\n            'name': 'No Clear Opinion',\n            'proposition': 'Pizza is the best food',\n            'text': 'I went to the store yesterday and bought some groceries. The weather was nice.',\n            'expected_range': (0.4, 0.6)\n        }\n    ]\n    \n    print(\"\\nExtended Test Cases\")\n    print(\"=\" * 50)\n    \n    for case in extended_cases:\n        score, breakdown = pipeline.measure_belief(case['proposition'], case['text'])\n        \n        print(f\"\\nCase: {case['name']}\")\n        print(f\"Proposition: {case['proposition']}\")\n        print(f\"Text: {case['text']}\")\n        print(f\"Score: {score:.3f}\")\n        print(f\"Expected: {case['expected_range']}\")\n        \n        in_range = case['expected_range'][0] <= score <= case['expected_range'][1]\n        print(f\"✓ Result: {'PASS' if in_range else 'REVIEW'}\")\n\n# Simple CLI interface for interactive testing\ndef interactive_mode():\n    \"\"\"Interactive mode for testing the pipeline.\"\"\"\n    pipeline = BeliefMeasurementPipeline()\n    print(\"Belief Measurement Pipeline - Interactive Mode\")\n    print(\"=\" * 50)\n    print(\"Enter 'quit' to exit\\n\")\n    \n    while True:\n        proposition = input(\"Enter proposition: \").strip()\n        if proposition.lower() == 'quit':\n            break\n            \n        text = input(\"Enter text to analyze: \").strip()\n        if text.lower() == 'quit':\n            break\n        \n        if not proposition or not text:\n            print(\"Both proposition and text are required.\\n\")\n            continue\n        \n        score, breakdown = pipeline.measure_belief(proposition, text)\n        \n        print(f\"\\n--- Results ---\")\n        print(f\"Belief Score: {score:.3f}\")\n        \n        # Interpret score\n        if score >= 0.8:\n            interpretation = \"Strong Agreement\"\n        elif score >= 0.6:\n            interpretation = \"Agreement\"\n        elif score >= 0.4:\n            interpretation = \"Neutral/Mixed\"\n        elif score >= 0.2:\n            interpretation = \"Disagreement\"\n        else:\n            interpretation = \"Strong Disagreement\"\n        \n        print(f\"Interpretation: {interpretation}\")\n        print(f\"Agreement signals: {breakdown['agreement_signals']}\")\n        print(f\"Disagreement signals: {breakdown['disagreement_signals']}\")\n        print(f\"Semantic similarity: {breakdown['semantic_similarity']:.3f}\")\n        print(\"-\" * 30)\n\nif __name__ == \"__main__\":\n    import sys\n    \n    if len(sys.argv) > 1 and sys.argv[1] == 'interactive':\n        interactive_mode()\n    else:\n        test_pipeline()\n        extended_test()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T00:49:47.483528Z","iopub.execute_input":"2025-07-20T00:49:47.484012Z","iopub.status.idle":"2025-07-20T00:49:47.523141Z","shell.execute_reply.started":"2025-07-20T00:49:47.483990Z","shell.execute_reply":"2025-07-20T00:49:47.522458Z"}},"outputs":[{"name":"stdout","text":"Testing Belief Measurement Pipeline\n==================================================\n\nTest Case 1:\nProposition: Climate change is a serious threat\nText: I absolutely agree that climate change poses a significant danger to our planet.\nScore: 0.795\nExpected Range: (0.8, 1.0)\n✓ In Expected Range: False\nBreakdown: {'final_score': 0.7954629629629631, 'semantic_similarity': 0.4875, 'context_sentiment': 1.0, 'agreement_signals': 3, 'disagreement_signals': 0, 'neutral_signals': 0, 'avg_agreement': 0.8333333333333334, 'avg_disagreement': None, 'components_used': 3}\n------------------------------\n\nTest Case 2:\nProposition: Climate change is a serious threat\nText: Climate change is completely overblown and not a real problem at all.\nScore: 0.526\nExpected Range: (0.0, 0.3)\n✓ In Expected Range: False\nBreakdown: {'final_score': 0.5257142857142857, 'semantic_similarity': 0.5857142857142856, 'context_sentiment': 0.5, 'agreement_signals': 0, 'disagreement_signals': 0, 'neutral_signals': 0, 'avg_agreement': None, 'avg_disagreement': None, 'components_used': 1}\n------------------------------\n\nTest Case 3:\nProposition: Exercise is beneficial for health\nText: I think exercise can be helpful but it depends on the person and situation.\nScore: 0.630\nExpected Range: (0.5, 0.7)\n✓ In Expected Range: True\nBreakdown: {'final_score': 0.6304761904761905, 'semantic_similarity': 0.3555555555555555, 'context_sentiment': 1.0, 'agreement_signals': 0, 'disagreement_signals': 0, 'neutral_signals': 1, 'avg_agreement': None, 'avg_disagreement': None, 'components_used': 3}\n------------------------------\n\nTest Case 4:\nProposition: Cats are better than dogs\nText: I love both cats and dogs equally. Both make wonderful pets.\nScore: 0.743\nExpected Range: (0.4, 0.6)\n✓ In Expected Range: False\nBreakdown: {'final_score': 0.7430769230769231, 'semantic_similarity': 0.45384615384615384, 'context_sentiment': 1.0, 'agreement_signals': 0, 'disagreement_signals': 0, 'neutral_signals': 0, 'avg_agreement': None, 'avg_disagreement': None, 'components_used': 2}\n------------------------------\n\nTest Case 5:\nProposition: Remote work increases productivity\nText: In my experience, working from home has made me much more efficient and productive.\nScore: 0.425\nExpected Range: (0.7, 0.9)\n✓ In Expected Range: False\nBreakdown: {'final_score': 0.425, 'semantic_similarity': 0.25, 'context_sentiment': 0.5, 'agreement_signals': 0, 'disagreement_signals': 0, 'neutral_signals': 0, 'avg_agreement': None, 'avg_disagreement': None, 'components_used': 1}\n------------------------------\n\nExtended Test Cases\n==================================================\n\nCase: Strong Agreement with Reasoning\nProposition: Education is important for society\nText: I firmly believe education is crucial. It empowers individuals, drives innovation, and creates a more informed citizenry.\nScore: 0.771\nExpected: (0.8, 1.0)\n✓ Result: REVIEW\n\nCase: Subtle Disagreement\nProposition: Social media is beneficial for mental health\nText: While social media connects people, I question whether it truly helps mental health. Studies suggest it might actually increase anxiety.\nScore: 0.427\nExpected: (0.2, 0.5)\n✓ Result: PASS\n\nCase: Neutral with Complexity\nProposition: Artificial intelligence will replace most jobs\nText: AI will certainly change the job market. Some roles will disappear, others will emerge. The net effect is hard to predict.\nScore: 0.413\nExpected: (0.4, 0.6)\n✓ Result: PASS\n\nCase: Strong Disagreement\nProposition: Vaccines are dangerous\nText: I completely disagree. Vaccines are safe and effective. This claim is utterly false and contradicts scientific evidence.\nScore: 0.264\nExpected: (0.0, 0.2)\n✓ Result: REVIEW\n\nCase: No Clear Opinion\nProposition: Pizza is the best food\nText: I went to the store yesterday and bought some groceries. The weather was nice.\nScore: 0.428\nExpected: (0.4, 0.6)\n✓ Result: PASS\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import re\n# import math\n# import json\n# from typing import List, Tuple, Dict, Optional\n# from collections import defaultdict\n# from abc import ABC, abstractmethod\n\n# # Abstract base class for different pipeline approaches\n# class BeliefMeasurementStrategy(ABC):\n#     @abstractmethod\n#     def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n#         pass\n\n# class PromptingBasedStrategy(BeliefMeasurementStrategy):\n#     \"\"\"\n#     Prompting-based approach that uses structured prompts to evaluate belief alignment.\n#     Simulates LLM reasoning through rule-based prompt interpretation.\n#     \"\"\"\n    \n#     def __init__(self):\n#         self.prompt_templates = {\n#             'direct_assessment': \"\"\"\n#             Analyze the following text to determine how much it agrees with the given proposition.\n            \n#             Proposition: \"{proposition}\"\n#             Text: \"{text}\"\n            \n#             Consider:\n#             1. Does the text explicitly agree or disagree with the proposition?\n#             2. What is the strength of the agreement/disagreement?\n#             3. Are there qualifying statements that moderate the position?\n#             4. Is the text neutral or irrelevant to the proposition?\n            \n#             Rate agreement on scale 0-10 where:\n#             0-1: Strong disagreement\n#             2-3: Disagreement  \n#             4-6: Neutral/Mixed\n#             7-8: Agreement\n#             9-10: Strong agreement\n#             \"\"\",\n            \n#             'comparative_assessment': \"\"\"\n#             Compare how much the text supports vs opposes the proposition:\n            \n#             Proposition: \"{proposition}\"\n#             Text: \"{text}\"\n            \n#             Evidence FOR the proposition in the text:\n#             Evidence AGAINST the proposition in the text:\n            \n#             Overall assessment (0-10 scale):\n#             \"\"\",\n            \n#             'reasoning_chain': \"\"\"\n#             Step-by-step analysis:\n            \n#             Proposition: \"{proposition}\"\n#             Text: \"{text}\"\n            \n#             Step 1: What is the main claim in the text?\n#             Step 2: How does this claim relate to the proposition?\n#             Step 3: What supporting evidence is provided?\n#             Step 4: Are there any contradictions or qualifications?\n#             Step 5: Overall belief alignment (0-10):\n#             \"\"\"\n#         }\n    \n#     def _simulate_llm_response(self, prompt: str, proposition: str, text: str) -> Dict:\n#         \"\"\"\n#         Simulate LLM response using rule-based reasoning.\n#         In production, this would call an actual LLM API.\n#         \"\"\"\n#         text_lower = text.lower()\n#         prop_lower = proposition.lower()\n        \n#         # Extract key phrases from proposition\n#         prop_keywords = set(re.findall(r'\\b\\w+\\b', prop_lower))\n#         text_keywords = set(re.findall(r'\\b\\w+\\b', text_lower))\n        \n#         keyword_overlap = len(prop_keywords.intersection(text_keywords)) / max(len(prop_keywords), 1)\n        \n#         # Analyze explicit stances\n#         strong_positive = any(phrase in text_lower for phrase in [\n#             'strongly agree', 'completely agree', 'absolutely', 'definitely true',\n#             'without doubt', 'certainly', 'undoubtedly'\n#         ])\n        \n#         positive = any(phrase in text_lower for phrase in [\n#             'agree', 'support', 'believe', 'yes', 'correct', 'true', 'right'\n#         ])\n        \n#         strong_negative = any(phrase in text_lower for phrase in [\n#             'strongly disagree', 'completely wrong', 'absolutely not', 'definitely false',\n#             'never', 'utterly false', 'completely disagree'\n#         ])\n        \n#         negative = any(phrase in text_lower for phrase in [\n#             'disagree', 'oppose', 'no', 'false', 'wrong', 'incorrect', 'dispute'\n#         ])\n        \n#         neutral = any(phrase in text_lower for phrase in [\n#             'neutral', 'mixed', 'depends', 'complicated', 'unsure', 'both sides'\n#         ])\n        \n#         # Simulate reasoning\n#         reasoning = {\n#             'keyword_overlap': keyword_overlap,\n#             'explicit_stance': None,\n#             'confidence': 0.5,\n#             'evidence_for': [],\n#             'evidence_against': [],\n#             'qualifications': []\n#         }\n        \n#         # Determine stance\n#         if strong_positive:\n#             reasoning['explicit_stance'] = 'strong_agree'\n#             reasoning['confidence'] = 0.9\n#             reasoning['score'] = 9\n#         elif positive:\n#             reasoning['explicit_stance'] = 'agree'\n#             reasoning['confidence'] = 0.7\n#             reasoning['score'] = 7\n#         elif strong_negative:\n#             reasoning['explicit_stance'] = 'strong_disagree'\n#             reasoning['confidence'] = 0.9\n#             reasoning['score'] = 1\n#         elif negative:\n#             reasoning['explicit_stance'] = 'disagree'\n#             reasoning['confidence'] = 0.7\n#             reasoning['score'] = 3\n#         elif neutral:\n#             reasoning['explicit_stance'] = 'neutral'\n#             reasoning['confidence'] = 0.6\n#             reasoning['score'] = 5\n#         else:\n#             # Use keyword overlap and context\n#             if keyword_overlap > 0.5:\n#                 reasoning['score'] = 5 + int(keyword_overlap * 3)\n#             else:\n#                 reasoning['score'] = 5  # Default neutral\n        \n#         # Adjust based on keyword overlap\n#         if reasoning.get('score'):\n#             if keyword_overlap < 0.2:\n#                 reasoning['score'] = max(4, min(6, reasoning['score']))  # Force toward neutral\n        \n#         return reasoning\n    \n#     def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n#         \"\"\"Measure belief using prompting-based approach.\"\"\"\n#         if not proposition.strip() or not text.strip():\n#             return 0.5, {'error': 'Empty proposition or text', 'method': 'prompting'}\n        \n#         # Use multiple prompt templates for robust assessment\n#         results = []\n#         detailed_analysis = {}\n        \n#         for template_name, template in self.prompt_templates.items():\n#             prompt = template.format(proposition=proposition, text=text)\n#             response = self._simulate_llm_response(prompt, proposition, text)\n            \n#             if 'score' in response:\n#                 # Convert 0-10 scale to 0-1\n#                 normalized_score = response['score'] / 10.0\n#                 results.append(normalized_score)\n#                 detailed_analysis[template_name] = response\n        \n#         # Ensemble the results\n#         if results:\n#             final_score = sum(results) / len(results)\n#         else:\n#             final_score = 0.5\n        \n#         # Ensure score is in [0, 1]\n#         final_score = max(0.0, min(1.0, final_score))\n        \n#         breakdown = {\n#             'final_score': final_score,\n#             'method': 'prompting',\n#             'individual_scores': results,\n#             'detailed_analysis': detailed_analysis,\n#             'num_prompts_used': len(results)\n#         }\n        \n#         return final_score, breakdown\n\n\n# class LogProbBasedStrategy(BeliefMeasurementStrategy):\n#     \"\"\"\n#     LogProb-based approach that estimates belief by comparing log probabilities\n#     of agreement vs disagreement continuations.\n#     \"\"\"\n    \n#     def __init__(self):\n#         # Simulated vocabulary with log probabilities\n#         # In production, this would use actual model logprobs\n#         self.vocab_logprobs = self._build_simulated_vocab()\n        \n#         # Template continuations to test\n#         self.agreement_templates = [\n#             \"This statement is {token}\",\n#             \"I {token} with this\",\n#             \"This is {token}\",\n#             \"The text {token} the proposition\"\n#         ]\n        \n#         self.agreement_tokens = ['true', 'correct', 'right', 'accurate', 'agree', 'support']\n#         self.disagreement_tokens = ['false', 'wrong', 'incorrect', 'disagree', 'oppose', 'dispute']\n#         self.neutral_tokens = ['unclear', 'mixed', 'neutral', 'uncertain']\n    \n#     def _build_simulated_vocab(self) -> Dict[str, float]:\n#         \"\"\"Build simulated vocabulary with log probabilities.\"\"\"\n#         # Simulate log probabilities for common words\n#         # In production, these would come from actual model\n#         vocab = {\n#             'true': -1.5, 'false': -1.8, 'correct': -2.1, 'wrong': -1.9,\n#             'right': -1.7, 'incorrect': -2.3, 'accurate': -2.8,\n#             'agree': -1.6, 'disagree': -2.0, 'support': -2.2, 'oppose': -2.5,\n#             'dispute': -3.1, 'unclear': -2.7, 'mixed': -2.9, 'neutral': -2.4,\n#             'uncertain': -2.8, 'definitely': -2.3, 'probably': -1.8,\n#             'maybe': -2.1, 'never': -2.2, 'always': -2.4\n#         }\n#         return vocab\n    \n#     def _calculate_context_logprob(self, context: str, token: str) -> float:\n#         \"\"\"\n#         Calculate log probability of token given context.\n#         Simulates model behavior based on context analysis.\n#         \"\"\"\n#         base_logprob = self.vocab_logprobs.get(token, -4.0)  # Default for unknown tokens\n        \n#         context_lower = context.lower()\n        \n#         # Boost probability if context supports the token\n#         if token in ['true', 'correct', 'right', 'accurate', 'agree', 'support']:\n#             if any(phrase in context_lower for phrase in ['i think', 'believe', 'support', 'agree']):\n#                 base_logprob += 1.0\n#             elif any(phrase in context_lower for phrase in ['disagree', 'oppose', 'wrong']):\n#                 base_logprob -= 1.5\n        \n#         elif token in ['false', 'wrong', 'incorrect', 'disagree', 'oppose']:\n#             if any(phrase in context_lower for phrase in ['disagree', 'oppose', 'wrong']):\n#                 base_logprob += 1.0\n#             elif any(phrase in context_lower for phrase in ['agree', 'support', 'correct']):\n#                 base_logprob -= 1.5\n        \n#         # Context relevance boost\n#         prop_words = set(re.findall(r'\\b\\w+\\b', context_lower))\n#         if token in prop_words:\n#             base_logprob += 0.5\n        \n#         return base_logprob\n    \n#     def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n#         \"\"\"Measure belief using log probability approach.\"\"\"\n#         if not proposition.strip() or not text.strip():\n#             return 0.5, {'error': 'Empty proposition or text', 'method': 'logprob'}\n        \n#         # Create context by combining proposition and text\n#         context = f\"Proposition: {proposition}\\nText: {text}\\n\"\n        \n#         # Calculate log probabilities for different token types\n#         agreement_logprobs = []\n#         disagreement_logprobs = []\n#         neutral_logprobs = []\n        \n#         for template in self.agreement_templates:\n#             for token in self.agreement_tokens:\n#                 filled_template = template.format(token=token)\n#                 full_context = context + filled_template\n#                 logprob = self._calculate_context_logprob(full_context, token)\n#                 agreement_logprobs.append(logprob)\n            \n#             for token in self.disagreement_tokens:\n#                 filled_template = template.format(token=token)\n#                 full_context = context + filled_template\n#                 logprob = self._calculate_context_logprob(full_context, token)\n#                 disagreement_logprobs.append(logprob)\n            \n#             for token in self.neutral_tokens:\n#                 filled_template = template.format(token=token)\n#                 full_context = context + filled_template\n#                 logprob = self._calculate_context_logprob(full_context, token)\n#                 neutral_logprobs.append(logprob)\n        \n#         # Calculate average log probabilities\n#         avg_agreement = sum(agreement_logprobs) / len(agreement_logprobs) if agreement_logprobs else -4.0\n#         avg_disagreement = sum(disagreement_logprobs) / len(disagreement_logprobs) if disagreement_logprobs else -4.0\n#         avg_neutral = sum(neutral_logprobs) / len(neutral_logprobs) if neutral_logprobs else -4.0\n        \n#         # Convert to probabilities using softmax\n#         logprobs = [avg_agreement, avg_disagreement, avg_neutral]\n#         max_logprob = max(logprobs)\n#         normalized_logprobs = [lp - max_logprob for lp in logprobs]\n        \n#         exp_probs = [math.exp(lp) for lp in normalized_logprobs]\n#         sum_exp = sum(exp_probs)\n        \n#         prob_agreement = exp_probs[0] / sum_exp\n#         prob_disagreement = exp_probs[1] / sum_exp\n#         prob_neutral = exp_probs[2] / sum_exp\n        \n#         # Convert to belief score (0 = disagree, 0.5 = neutral, 1 = agree)\n#         belief_score = prob_agreement + 0.5 * prob_neutral\n        \n#         breakdown = {\n#             'final_score': belief_score,\n#             'method': 'logprob',\n#             'prob_agreement': prob_agreement,\n#             'prob_disagreement': prob_disagreement,\n#             'prob_neutral': prob_neutral,\n#             'avg_agreement_logprob': avg_agreement,\n#             'avg_disagreement_logprob': avg_disagreement,\n#             'avg_neutral_logprob': avg_neutral,\n#             'num_templates': len(self.agreement_templates)\n#         }\n        \n#         return belief_score, breakdown\n\n# class PatternBasedStrategy(BeliefMeasurementStrategy):\n#     \"\"\"\n#     Original pattern-based approach using regex patterns and rule-based analysis.\n#     A pipeline to measure belief alignment between a proposition and free-form text.\n#     Returns a score in [0,1] where 0=strongly disagrees, 0.5=neutral, 1=strongly agrees.\n#     \"\"\"\n    \n#     def __init__(self):\n#         # Agreement indicators with weights\n#         self.agreement_markers = {\n#             'strong_agree': {\n#                 'patterns': [r'\\b(absolutely|completely|totally|entirely|fully)\\s+(agree|support|believe|endorse)',\n#                            r'\\b(strongly|firmly)\\s+(agree|support|believe|endorse)',\n#                            r'\\b(without\\s+doubt|undoubtedly|certainly|definitely)\\b.*\\b(true|correct|right)\\b',\n#                            r'\\bI\\s+(completely|totally|absolutely|strongly)\\s+(agree|support|believe)\\b'],\n#                 'weight': 0.9\n#             },\n#             'agree': {\n#                 'patterns': [r'\\b(agree|support|believe|endorse|accept|embrace)\\b',\n#                            r'\\b(yes|correct|true|right|accurate|valid)\\b',\n#                            r'\\bI\\s+(think|believe|feel)\\s+.*\\b(true|correct|right)\\b'],\n#                 'weight': 0.7\n#             },\n#             'weak_agree': {\n#                 'patterns': [r'\\b(somewhat|partially|largely|mostly|generally)\\s+(agree|support|believe)',\n#                            r'\\b(tend\\s+to|inclined\\s+to)\\s+(agree|believe|support)',\n#                            r'\\b(probably|likely)\\s+(true|correct|right)\\b'],\n#                 'weight': 0.6\n#             }\n#         }\n        \n#         # Disagreement indicators\n#         self.disagreement_markers = {\n#             'strong_disagree': {\n#                 'patterns': [r'\\b(absolutely|completely|totally|entirely|strongly)\\s+(disagree|oppose|reject)',\n#                            r'\\b(never|not\\s+at\\s+all|in\\s+no\\s+way)\\b',\n#                            r'\\b(completely|utterly|totally)\\s+(false|wrong|incorrect)',\n#                            r'\\bI\\s+(completely|totally|absolutely|strongly)\\s+(disagree|oppose|reject)\\b'],\n#                 'weight': 0.1\n#             },\n#             'disagree': {\n#                 'patterns': [r'\\b(disagree|oppose|reject|deny|refute|dispute)\\b',\n#                            r'\\b(no|false|wrong|incorrect|invalid|untrue)\\b',\n#                            r'\\bI\\s+(don\\'?t|do\\s+not)\\s+(agree|believe|support|think)\\b'],\n#                 'weight': 0.3\n#             },\n#             'weak_disagree': {\n#                 'patterns': [r'\\b(somewhat|partially)\\s+(disagree|oppose)',\n#                            r'\\b(doubt|question|skeptical|uncertain)\\b',\n#                            r'\\b(probably|likely)\\s+(false|wrong|incorrect)\\b'],\n#                 'weight': 0.4\n#             }\n#         }\n        \n#         # Neutral indicators\n#         self.neutral_markers = {\n#             'patterns': [r'\\b(neutral|undecided|unsure|uncertain|mixed\\s+feelings)\\b',\n#                         r'\\b(both\\s+sides|on\\s+one\\s+hand.*on\\s+the\\s+other)\\b',\n#                         r'\\b(depends|it\\'?s\\s+complicated|not\\s+sure)\\b'],\n#             'weight': 0.5\n#         }\n        \n#     def handle_negations(self, text: str) -> Tuple[str, bool]:\n#         \"\"\"Handle negations that might flip the meaning.\"\"\"\n#         # Simple negation patterns\n#         negation_patterns = [\n#             (r'\\b(do\\s+not|don\\'t|does\\s+not|doesn\\'t|did\\s+not|didn\\'t)\\s+', ''),\n#             (r'\\b(not|never|no)\\s+', ''),\n#             (r'\\b(isn\\'t|aren\\'t|wasn\\'t|weren\\'t|won\\'t|wouldn\\'t|can\\'t|couldn\\'t)\\b', ''),\n#         ]\n        \n#         negation_count = 0\n#         processed_text = text.lower()\n        \n#         for pattern, replacement in negation_patterns:\n#             matches = re.findall(pattern, processed_text, re.IGNORECASE)\n#             negation_count += len(matches)\n#             processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)\n        \n#         return processed_text, negation_count % 2 == 1  # Odd number of negations = flipped\n\n#     def extract_agreement_signals(self, text: str, proposition: str) -> Dict[str, List[float]]:\n#         \"\"\"Extract agreement/disagreement signals from text.\"\"\"\n#         text_lower = text.lower()\n#         prop_lower = proposition.lower()\n        \n#         # Handle negations\n#         processed_text, is_negated = self.handle_negations(text)\n        \n#         # Combine text and proposition for context-aware matching\n#         combined_text = f\"{prop_lower} {processed_text}\"\n        \n#         signals = defaultdict(list)\n        \n#         # Check agreement markers\n#         for level, markers in self.agreement_markers.items():\n#             for pattern in markers['patterns']:\n#                 matches = re.findall(pattern, combined_text, re.IGNORECASE)\n#                 if matches:\n#                     weight = markers['weight']\n#                     if is_negated:\n#                         weight = 1.0 - weight  # Flip due to negation\n#                     signals['agreement'].extend([weight] * len(matches))\n        \n#         # Check disagreement markers\n#         for level, markers in self.disagreement_markers.items():\n#             for pattern in markers['patterns']:\n#                 matches = re.findall(pattern, combined_text, re.IGNORECASE)\n#                 if matches:\n#                     weight = markers['weight']\n#                     if is_negated:\n#                         weight = 1.0 - weight  # Flip due to negation\n#                     signals['disagreement'].extend([weight] * len(matches))\n        \n#         # Check neutral markers\n#         for pattern in self.neutral_markers['patterns']:\n#             matches = re.findall(pattern, combined_text, re.IGNORECASE)\n#             if matches:\n#                 signals['neutral'].extend([self.neutral_markers['weight']] * len(matches))\n        \n#         return signals\n\n#     def calculate_semantic_similarity(self, text: str, proposition: str) -> float:\n#         \"\"\"\n#         Simple semantic similarity based on word overlap and key terms.\n#         In a production system, this would use embeddings.\n#         \"\"\"\n#         # Tokenize and clean\n#         def tokenize(s):\n#             return set(re.findall(r'\\b\\w+\\b', s.lower()))\n        \n#         text_tokens = tokenize(text)\n#         prop_tokens = tokenize(proposition)\n        \n#         if not prop_tokens:\n#             return 0.5\n        \n#         # Calculate overlap\n#         intersection = text_tokens.intersection(prop_tokens)\n#         union = text_tokens.union(prop_tokens)\n        \n#         if not union:\n#             return 0.5\n        \n#         jaccard_similarity = len(intersection) / len(union)\n        \n#         # Boost for exact proposition mentions\n#         prop_words = proposition.lower().split()\n#         text_lower = text.lower()\n        \n#         exact_mentions = sum(1 for word in prop_words if word in text_lower)\n#         mention_boost = min(exact_mentions / len(prop_words), 0.3)\n        \n#         return min(jaccard_similarity + mention_boost, 1.0)\n    \n#     def analyze_context_sentiment(self, text: str, proposition: str) -> float:\n#         \"\"\"\n#         Analyze sentiment in context of the proposition.\n#         Simple implementation - in production would use proper sentiment analysis.\n#         \"\"\"\n#         text_lower = text.lower()\n        \n#         # Positive sentiment words\n#         positive_words = ['good', 'great', 'excellent', 'wonderful', 'amazing', 'fantastic',\n#                          'beneficial', 'helpful', 'valuable', 'important', 'necessary',\n#                          'essential', 'vital', 'crucial', 'significant']\n        \n#         # Negative sentiment words\n#         negative_words = ['bad', 'terrible', 'awful', 'horrible', 'wrong', 'harmful',\n#                          'dangerous', 'problematic', 'concerning', 'worrying', 'alarming',\n#                          'unnecessary', 'useless', 'pointless', 'wasteful']\n        \n#         positive_count = sum(1 for word in positive_words if word in text_lower)\n#         negative_count = sum(1 for word in negative_words if word in text_lower)\n        \n#         if positive_count == 0 and negative_count == 0:\n#             return 0.5\n        \n#         total = positive_count + negative_count\n#         return positive_count / total\n    \n#     def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n#         \"\"\"\n#         Main method to measure belief alignment.\n#         Returns belief score and detailed breakdown.\n#         \"\"\"\n#         if not proposition.strip() or not text.strip():\n#             return 0.5, {'error': 'Empty proposition or text', 'method': 'pattern'}\n        \n#         # Extract signals\n#         signals = self.extract_agreement_signals(text, proposition)\n        \n#         # Calculate components\n#         semantic_sim = self.calculate_semantic_similarity(text, proposition)\n#         context_sentiment = self.analyze_context_sentiment(text, proposition)\n        \n#         # Aggregate agreement/disagreement signals\n#         agreement_scores = signals.get('agreement', [])\n#         disagreement_scores = signals.get('disagreement', [])\n#         neutral_scores = signals.get('neutral', [])\n        \n#         # Calculate weighted averages\n#         if agreement_scores:\n#             avg_agreement = sum(agreement_scores) / len(agreement_scores)\n#         else:\n#             avg_agreement = None\n            \n#         if disagreement_scores:\n#             avg_disagreement = sum(disagreement_scores) / len(disagreement_scores)\n#         else:\n#             avg_disagreement = None\n        \n#         # Combine signals with weights\n#         components = []\n#         weights = []\n        \n#         # Primary signals (explicit agreement/disagreement)\n#         if avg_agreement is not None:\n#             components.append(avg_agreement)\n#             weights.append(0.5)  # High weight for explicit agreement\n        \n#         if avg_disagreement is not None:\n#             components.append(avg_disagreement)\n#             weights.append(0.5)  # High weight for explicit disagreement\n        \n#         # Secondary signals\n#         if semantic_sim > 0:\n#             components.append(0.5 + (semantic_sim - 0.5) * 0.3)  # Moderate influence\n#             weights.append(0.2)\n        \n#         if context_sentiment != 0.5:\n#             components.append(context_sentiment)\n#             weights.append(0.2)\n        \n#         # Handle neutral signals\n#         if neutral_scores:\n#             components.append(0.5)\n#             weights.append(0.3)\n        \n#         # Default to neutral if no signals\n#         if not components:\n#             final_score = 0.5\n#         else:\n#             # Weighted average\n#             final_score = sum(c * w for c, w in zip(components, weights)) / sum(weights)\n        \n#         # Ensure score is in [0, 1]\n#         final_score = max(0.0, min(1.0, final_score))\n        \n#         # Prepare detailed breakdown\n#         breakdown = {\n#             'final_score': final_score,\n#             'method': 'pattern',\n#             'semantic_similarity': semantic_sim,\n#             'context_sentiment': context_sentiment,\n#             'agreement_signals': len(agreement_scores),\n#             'disagreement_signals': len(disagreement_scores),\n#             'neutral_signals': len(neutral_scores),\n#             'avg_agreement': avg_agreement,\n#             'avg_disagreement': avg_disagreement,\n#             'components_used': len(components)\n#         }\n        \n#         return final_score, breakdown\n\n\n# class BeliefMeasurementPipeline:\n#     \"\"\"\n#     Unified pipeline supporting multiple belief measurement strategies:\n#     - Pattern-based (regex + rules)\n#     - Prompting-based (structured prompts)  \n#     - LogProb-based (probability comparison)\n#     - Ensemble (combination of multiple strategies)\n#     \"\"\"\n    \n#     def __init__(self, strategy: str = 'ensemble'):\n#         \"\"\"\n#         Initialize pipeline with specified strategy.\n        \n#         Args:\n#             strategy: 'pattern', 'prompting', 'logprob', or 'ensemble'\n#         \"\"\"\n#         self.strategies = {\n#             'pattern': PatternBasedStrategy(),\n#             'prompting': PromptingBasedStrategy(), \n#             'logprob': LogProbBasedStrategy()\n#         }\n        \n#         self.strategy_name = strategy\n#         if strategy == 'ensemble':\n#             self.active_strategies = list(self.strategies.values())\n#         else:\n#             self.active_strategies = [self.strategies[strategy]]\n    \n#     def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n#         \"\"\"\n#         Measure belief using the configured strategy/strategies.\n#         \"\"\"\n#         if not proposition.strip() or not text.strip():\n#             return 0.5, {'error': 'Empty proposition or text'}\n        \n#         if self.strategy_name == 'ensemble':\n#             return self._ensemble_measure(proposition, text)\n#         else:\n#             return self.active_strategies[0].measure_belief(proposition, text)\n    \n#     def _ensemble_measure(self, proposition: str, text: str) -> Tuple[float, Dict]:\n#         \"\"\"Combine multiple strategies using ensemble approach.\"\"\"\n#         results = []\n#         detailed_results = {}\n        \n#         # Get results from each strategy\n#         for name, strategy in self.strategies.items():\n#             try:\n#                 score, breakdown = strategy.measure_belief(proposition, text)\n#                 results.append(score)\n#                 detailed_results[name] = {\n#                     'score': score,\n#                     'breakdown': breakdown\n#                 }\n#             except Exception as e:\n#                 detailed_results[name] = {\n#                     'error': str(e)\n#                 }\n        \n#         if not results:\n#             return 0.5, {'error': 'All strategies failed'}\n        \n#         # Weighted ensemble (can be adjusted based on strategy reliability)\n#         weights = {\n#             'pattern': 0.4,    # Good for explicit statements\n#             'prompting': 0.4,  # Good for nuanced reasoning\n#             'logprob': 0.2     # Good for implicit signals\n#         }\n        \n#         weighted_score = 0\n#         total_weight = 0\n        \n#         for i, (name, strategy) in enumerate(self.strategies.items()):\n#             if name in detailed_results and 'score' in detailed_results[name]:\n#                 weight = weights.get(name, 1.0 / len(self.strategies))\n#                 weighted_score += detailed_results[name]['score'] * weight\n#                 total_weight += weight\n        \n#         final_score = weighted_score / total_weight if total_weight > 0 else 0.5\n        \n#         # Calculate agreement between strategies (confidence measure)\n#         if len(results) > 1:\n#             mean_score = sum(results) / len(results)\n#             variance = sum((s - mean_score) ** 2 for s in results) / len(results)\n#             agreement = 1.0 - min(variance * 4, 1.0)  # Higher agreement = lower variance\n#         else:\n#             agreement = 1.0\n        \n#         breakdown = {\n#             'final_score': final_score,\n#             'method': 'ensemble',\n#             'strategy_results': detailed_results,\n#             'individual_scores': results,\n#             'agreement_score': agreement,\n#             'weights_used': weights\n#         }\n        \n#         return final_score, breakdown\n\n\n# def interactive_mode():\n#     \"\"\"Interactive mode for testing the pipeline.\"\"\"\n#     print(\"Belief Measurement Pipeline - Interactive Mode\")\n#     print(\"=\" * 50)\n#     print(\"Available strategies: pattern, prompting, logprob, ensemble\")\n#     print(\"Type 'quit' to exit\")\n#     print()\n    \n#     while True:\n#         strategy = input(\"Select strategy (default: ensemble): \").strip()\n#         if strategy.lower() == 'quit':\n#             break\n#         if not strategy:\n#             strategy = 'ensemble'\n        \n#         if strategy not in ['pattern', 'prompting', 'logprob', 'ensemble']:\n#             print(\"Invalid strategy. Please choose from: pattern, prompting, logprob, ensemble\")\n#             continue\n        \n#         pipeline = BeliefMeasurementPipeline(strategy=strategy)\n        \n#         print(f\"\\nUsing {strategy} strategy\")\n#         proposition = input(\"Enter proposition: \").strip()\n#         if proposition.lower() == 'quit':\n#             break\n        \n#         text = input(\"Enter text: \").strip()\n#         if text.lower() == 'quit':\n#             break\n        \n#         if proposition and text:\n#             score, breakdown = pipeline.measure_belief(proposition, text)\n#             print(f\"\\nBelief Score: {score:.3f}\")\n#             print(f\"Method: {breakdown.get('method', 'unknown')}\")\n            \n#             if strategy == 'ensemble':\n#                 print(\"\\nStrategy Breakdown:\")\n#                 for strat_name, result in breakdown.get('strategy_results', {}).items():\n#                     if 'score' in result:\n#                         print(f\"  {strat_name}: {result['score']:.3f}\")\n#                 print(f\"Agreement Score: {breakdown.get('agreement_score', 0):.3f}\")\n            \n#             print(\"-\" * 30)\n#         else:\n#             print(\"Please provide both proposition and text.\")\n\n\n# # Test all strategies\n# def comprehensive_test():\n#     \"\"\"Test all strategies on the same test cases.\"\"\"\n#     test_cases = [\n#         {\n#             'name': 'Strong Agreement',\n#             'proposition': 'Climate change is a serious threat',\n#             'text': 'I absolutely agree that climate change poses a significant danger to our planet and requires immediate action.',\n#             'expected_range': (0.8, 1.0)\n#         },\n#         {\n#             'name': 'Strong Disagreement', \n#             'proposition': 'Vaccines are dangerous',\n#             'text': 'I completely disagree. Vaccines are safe, effective, and this claim is utterly false according to scientific evidence.',\n#             'expected_range': (0.0, 0.2)\n#         },\n#         {\n#             'name': 'Qualified Agreement',\n#             'proposition': 'Remote work increases productivity',\n#             'text': 'I think remote work can increase productivity for some people, but it depends on the individual and the type of work.',\n#             'expected_range': (0.5, 0.8)\n#         },\n#         {\n#             'name': 'Neutral/Irrelevant',\n#             'proposition': 'Pizza is the best food',\n#             'text': 'I went to the store yesterday and bought some groceries. The weather was nice and I saw a dog.',\n#             'expected_range': (0.4, 0.6)\n#         },\n#         {\n#             'name': 'Subtle Disagreement',\n#             'proposition': 'Social media improves mental health',\n#             'text': 'While social media connects people, research suggests it might actually increase anxiety and depression rather than helping.',\n#             'expected_range': (0.2, 0.5)\n#         }\n#     ]\n    \n#     strategies = ['pattern', 'prompting', 'logprob', 'ensemble']\n    \n#     print(\"Comprehensive Strategy Comparison\")\n#     print(\"=\" * 60)\n    \n#     for case in test_cases:\n#         print(f\"\\nTest Case: {case['name']}\")\n#         print(f\"Proposition: {case['proposition']}\")\n#         print(f\"Text: {case['text']}\")\n#         print(f\"Expected Range: {case['expected_range']}\")\n#         print(\"-\" * 40)\n        \n#         for strategy in strategies:\n#             pipeline = BeliefMeasurementPipeline(strategy=strategy)\n#             score, breakdown = pipeline.measure_belief(case['proposition'], case['text'])\n            \n#             in_range = case['expected_range'][0] <= score <= case['expected_range'][1]\n#             status = \"✓ PASS\" if in_range else \"✗ REVIEW\"\n            \n#             print(f\"{strategy:>12}: {score:.3f} {status}\")\n            \n#             # Show key insights for ensemble\n#             if strategy == 'ensemble' and 'strategy_results' in breakdown:\n#                 individual_scores = []\n#                 for strat_name, result in breakdown['strategy_results'].items():\n#                     if 'score' in result:\n#                         individual_scores.append(f\"{strat_name}: {result['score']:.3f}\")\n#                 print(f\"            Individual: {', '.join(individual_scores)}\")\n#                 print(f\"            Agreement: {breakdown.get('agreement_score', 0):.3f}\")\n        \n#         print()\n\n\n# def strategy_analysis():\n#     \"\"\"Analyze strengths and weaknesses of each strategy.\"\"\"\n#     pipeline_pattern = BeliefMeasurementPipeline('pattern')\n#     pipeline_prompting = BeliefMeasurementPipeline('prompting') \n#     pipeline_logprob = BeliefMeasurementPipeline('logprob')\n    \n#     analysis_cases = [\n#         {\n#             'name': 'Explicit Agreement',\n#             'proposition': 'Education is important',\n#             'text': 'I strongly agree that education is crucial for society.',\n#             'expected_best': 'pattern'  # Should excel at explicit markers\n#         },\n#         {\n#             'name': 'Implicit Reasoning',\n#             'proposition': 'Exercise prevents disease',\n#             'text': 'Regular physical activity strengthens the immune system, improves cardiovascular health, and reduces inflammation.',\n#             'expected_best': 'prompting'  # Should excel at implicit reasoning\n#         },\n#         {\n#             'name': 'Ambiguous Context',\n#             'proposition': 'Technology makes life better',\n#             'text': 'Technology has transformed how we work and communicate, though it also creates new challenges.',\n#             'expected_best': 'logprob'  # May handle uncertainty well\n#         }\n#     ]\n    \n#     print(\"\\nStrategy Analysis\")\n#     print(\"=\" * 40)\n    \n#     for case in analysis_cases:\n#         print(f\"\\nCase: {case['name']}\")\n#         print(f\"Expected best strategy: {case['expected_best']}\")\n        \n#         scores = {}\n#         scores['pattern'], _ = pipeline_pattern.measure_belief(case['proposition'], case['text'])\n#         scores['prompting'], _ = pipeline_prompting.measure_belief(case['proposition'], case['text'])  \n#         scores['logprob'], _ = pipeline_logprob.measure_belief(case['proposition'], case['text'])\n        \n#         # Find best performing strategy\n#         best_strategy = max(scores.items(), key=lambda x: abs(x[1] - 0.5))  # Most confident\n#         print(f\"Results: {scores}\")\n#         print(f\"Most confident: {best_strategy[0]} ({best_strategy[1]:.3f})\")\n#         print(f\"Matches expectation: {best_strategy[0] == case['expected_best']}\")\n\n\n# def demo_examples():\n#     \"\"\"Demonstrate the pipeline with example use cases.\"\"\"\n#     print(\"Belief Measurement Pipeline - Demo Examples\")\n#     print(\"=\" * 50)\n    \n#     examples = [\n#         {\n#             'proposition': 'Artificial intelligence will benefit humanity',\n#             'text': 'AI has tremendous potential to solve complex problems in healthcare, climate change, and education. While there are risks to manage, the benefits far outweigh the concerns when developed responsibly.'\n#         },\n#         {\n#             'proposition': 'Working from home is more productive',\n#             'text': 'I completely disagree with remote work being more productive. In my experience, office collaboration and direct supervision lead to much better results and team cohesion.'\n#         },\n#         {\n#             'proposition': 'Electric cars are the future of transportation',\n#             'text': 'Electric vehicles are becoming increasingly popular and the technology is improving rapidly. However, there are still challenges with charging infrastructure and battery costs that need to be addressed.'\n#         }\n#     ]\n    \n#     pipeline = BeliefMeasurementPipeline('ensemble')\n    \n#     for i, example in enumerate(examples, 1):\n#         print(f\"\\nExample {i}:\")\n#         print(f\"Proposition: {example['proposition']}\")\n#         print(f\"Text: {example['text']}\")\n        \n#         score, breakdown = pipeline.measure_belief(example['proposition'], example['text'])\n        \n#         print(f\"\\nOverall Belief Score: {score:.3f}\")\n        \n#         # Interpret the score\n#         if score >= 0.8:\n#             interpretation = \"Strong Agreement\"\n#         elif score >= 0.6:\n#             interpretation = \"Agreement\"\n#         elif score >= 0.4:\n#             interpretation = \"Neutral/Mixed\"\n#         elif score >= 0.2:\n#             interpretation = \"Disagreement\"\n#         else:\n#             interpretation = \"Strong Disagreement\"\n        \n#         print(f\"Interpretation: {interpretation}\")\n        \n#         # Show individual strategy scores\n#         print(\"Individual Strategy Scores:\")\n#         for strategy_name, result in breakdown.get('strategy_results', {}).items():\n#             if 'score' in result:\n#                 print(f\"  {strategy_name.capitalize()}: {result['score']:.3f}\")\n        \n#         print(f\"Strategy Agreement: {breakdown.get('agreement_score', 0):.3f}\")\n#         print(\"-\" * 50)\n\n\n# def performance_test():\n#     \"\"\"Test pipeline performance with various edge cases.\"\"\"\n#     print(\"Performance Test - Edge Cases\")\n#     print(\"=\" * 40)\n    \n#     edge_cases = [\n#         {\n#             'name': 'Empty strings',\n#             'proposition': '',\n#             'text': ''\n#         },\n#         {\n#             'name': 'Very short text',\n#             'proposition': 'Short test',\n#             'text': 'Yes.'\n#         },\n#         {\n#             'name': 'Long complex text',\n#             'proposition': 'Democracy is important',\n#             'text': '''Democracy, while not perfect, represents the best system of governance we have developed. \n#                       It allows for peaceful transitions of power, protects minority rights through constitutional frameworks,\n#                       and provides mechanisms for citizens to hold leaders accountable. However, it requires active \n#                       participation from informed citizens and strong institutions to function effectively. Recent challenges\n#                       to democratic norms in various countries highlight the fragility of these systems and the need for\n#                       constant vigilance to protect democratic values and processes.'''\n#         },\n#         {\n#             'name': 'Contradictory statements',\n#             'proposition': 'Exercise is good',\n#             'text': 'Exercise is definitely beneficial for health. However, I completely disagree that exercise is good because it can cause injuries.'\n#         },\n#         {\n#             'name': 'Multiple negations',\n#             'proposition': 'Smoking is harmful',\n#             'text': 'I do not think that smoking is not dangerous. It is not true that smoking does not cause health problems.'\n#         }\n#     ]\n    \n#     pipeline = BeliefMeasurementPipeline('ensemble')\n    \n#     for case in edge_cases:\n#         print(f\"\\nTest: {case['name']}\")\n#         print(f\"Proposition: '{case['proposition']}'\")\n#         print(f\"Text: '{case['text'][:100]}{'...' if len(case['text']) > 100 else ''}'\")\n        \n#         try:\n#             score, breakdown = pipeline.measure_belief(case['proposition'], case['text'])\n#             print(f\"Score: {score:.3f}\")\n#             print(f\"Status: {'✓ Success' if 'error' not in breakdown else '✗ Error: ' + breakdown['error']}\")\n#         except Exception as e:\n#             print(f\"Status: ✗ Exception: {str(e)}\")\n\n\n# def save_results_to_file(results: Dict, filename: str = 'belief_measurement_results.json'):\n#     \"\"\"Save test results to a JSON file for analysis.\"\"\"\n#     try:\n#         with open(filename, 'w') as f:\n#             json.dump(results, f, indent=2)\n#         print(f\"Results saved to {filename}\")\n#     except Exception as e:\n#         print(f\"Error saving results: {e}\")\n\n\n# def batch_analysis(test_data: List[Dict]) -> Dict:\n#     \"\"\"Run batch analysis on multiple test cases.\"\"\"\n#     print(\"Running Batch Analysis...\")\n    \n#     results = {\n#         'summary': {},\n#         'detailed_results': [],\n#         'strategy_performance': {}\n#     }\n    \n#     strategies = ['pattern', 'prompting', 'logprob', 'ensemble']\n#     strategy_scores = {strategy: [] for strategy in strategies}\n    \n#     for i, test_case in enumerate(test_data):\n#         case_results = {\n#             'case_id': i + 1,\n#             'proposition': test_case['proposition'],\n#             'text': test_case['text'],\n#             'strategy_scores': {}\n#         }\n        \n#         for strategy in strategies:\n#             pipeline = BeliefMeasurementPipeline(strategy=strategy)\n#             score, breakdown = pipeline.measure_belief(test_case['proposition'], test_case['text'])\n            \n#             case_results['strategy_scores'][strategy] = {\n#                 'score': score,\n#                 'method': breakdown.get('method', strategy)\n#             }\n#             strategy_scores[strategy].append(score)\n        \n#         results['detailed_results'].append(case_results)\n    \n#     # Calculate summary statistics\n#     for strategy in strategies:\n#         scores = strategy_scores[strategy]\n#         if scores:\n#             results['strategy_performance'][strategy] = {\n#                 'mean_score': sum(scores) / len(scores),\n#                 'min_score': min(scores),\n#                 'max_score': max(scores),\n#                 'score_variance': sum((s - sum(scores)/len(scores))**2 for s in scores) / len(scores)\n#             }\n    \n#     results['summary'] = {\n#         'total_cases': len(test_data),\n#         'strategies_tested': strategies,\n#         'most_confident_strategy': min(results['strategy_performance'].items(), \n#                                      key=lambda x: x[1]['score_variance'])[0]\n#     }\n    \n#     return results\n\n\n# if __name__ == \"__main__\":\n#     import sys\n    \n#     if len(sys.argv) > 1:\n#         command = sys.argv[1].lower()\n        \n#         if command == 'interactive':\n#             interactive_mode()\n#         elif command == 'comprehensive':\n#             comprehensive_test()\n#         elif command == 'analysis':\n#             strategy_analysis()\n#         elif command == 'demo':\n#             demo_examples()\n#         elif command == 'performance':\n#             performance_test()\n#         elif command == 'all':\n#             print(\"Running all tests...\\n\")\n#             comprehensive_test()\n#             strategy_analysis()\n#             demo_examples()\n#             performance_test()\n#         else:\n#             print(\"Available commands:\")\n#             print(\"  interactive  - Interactive mode for custom testing\")\n#             print(\"  comprehensive - Run comprehensive test suite\")\n#             print(\"  analysis     - Strategy analysis and comparison\")\n#             print(\"  demo         - Demonstrate with example use cases\")\n#             print(\"  performance  - Test edge cases and performance\")\n#             print(\"  all          - Run all tests\")\n#             print(\"\\nUsage: python script.py [command]\")\n#     else:\n#         # Default behavior - run comprehensive test and analysis\n#         print(\"Belief Measurement Pipeline\")\n#         print(\"=\" * 30)\n#         print(\"Running default test suite...\\n\")\n        \n#         comprehensive_test()\n#         strategy_analysis()\n        \n#         print(\"\\nFor more options, run: python script.py [command]\")\n#         print(\"Use 'python script.py interactive' for interactive testing\")\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T01:22:39.921224Z","iopub.execute_input":"2025-07-20T01:22:39.921496Z","iopub.status.idle":"2025-07-20T01:22:40.029291Z","shell.execute_reply.started":"2025-07-20T01:22:39.921474Z","shell.execute_reply":"2025-07-20T01:22:40.028537Z"}},"outputs":[{"name":"stdout","text":"Available commands:\n  interactive  - Interactive mode for custom testing\n  comprehensive - Run comprehensive test suite\n  analysis     - Strategy analysis and comparison\n  demo         - Demonstrate with example use cases\n  performance  - Test edge cases and performance\n  all          - Run all tests\n\nUsage: python script.py [command]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Scaling the project to all 3 dimension (prompting-based,logprob-based, embedding-based)","metadata":{}},{"cell_type":"code","source":"import re\nimport math\nimport json\nfrom typing import List, Tuple, Dict, Optional\nfrom collections import defaultdict\nfrom abc import ABC, abstractmethod\n\n# Abstract base class for different pipeline approaches\nclass BeliefMeasurementStrategy(ABC):\n    @abstractmethod\n    def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n        pass\n\nclass PromptingBasedStrategy(BeliefMeasurementStrategy):\n    \"\"\"\n    Prompting-based approach that uses structured prompts to evaluate belief alignment.\n    Simulates LLM reasoning through rule-based prompt interpretation.\n    \"\"\"\n    \n    def __init__(self):\n        self.prompt_templates = {\n            'direct_assessment': \"\"\"\n            Analyze the following text to determine how much it agrees with the given proposition.\n            \n            Proposition: \"{proposition}\"\n            Text: \"{text}\"\n            \n            Consider:\n            1. Does the text explicitly agree or disagree with the proposition?\n            2. What is the strength of the agreement/disagreement?\n            3. Are there qualifying statements that moderate the position?\n            4. Is the text neutral or irrelevant to the proposition?\n            \n            Rate agreement on scale 0-10 where:\n            0-1: Strong disagreement\n            2-3: Disagreement  \n            4-6: Neutral/Mixed\n            7-8: Agreement\n            9-10: Strong agreement\n            \"\"\",\n            \n            'comparative_assessment': \"\"\"\n            Compare how much the text supports vs opposes the proposition:\n            \n            Proposition: \"{proposition}\"\n            Text: \"{text}\"\n            \n            Evidence FOR the proposition in the text:\n            Evidence AGAINST the proposition in the text:\n            \n            Overall assessment (0-10 scale):\n            \"\"\",\n            \n            'reasoning_chain': \"\"\"\n            Step-by-step analysis:\n            \n            Proposition: \"{proposition}\"\n            Text: \"{text}\"\n            \n            Step 1: What is the main claim in the text?\n            Step 2: How does this claim relate to the proposition?\n            Step 3: What supporting evidence is provided?\n            Step 4: Are there any contradictions or qualifications?\n            Step 5: Overall belief alignment (0-10):\n            \"\"\"\n        }\n    \n    def _simulate_llm_response(self, prompt: str, proposition: str, text: str) -> Dict:\n        \"\"\"\n        Simulate LLM response using rule-based reasoning.\n        In production, this would call an actual LLM API.\n        \"\"\"\n        text_lower = text.lower()\n        prop_lower = proposition.lower()\n        \n        # Extract key phrases from proposition\n        prop_keywords = set(re.findall(r'\\b\\w+\\b', prop_lower))\n        text_keywords = set(re.findall(r'\\b\\w+\\b', text_lower))\n        \n        keyword_overlap = len(prop_keywords.intersection(text_keywords)) / max(len(prop_keywords), 1)\n        \n        # Analyze explicit stances\n        strong_positive = any(phrase in text_lower for phrase in [\n            'strongly agree', 'completely agree', 'absolutely', 'definitely true',\n            'without doubt', 'certainly', 'undoubtedly'\n        ])\n        \n        positive = any(phrase in text_lower for phrase in [\n            'agree', 'support', 'believe', 'yes', 'correct', 'true', 'right'\n        ])\n        \n        strong_negative = any(phrase in text_lower for phrase in [\n            'strongly disagree', 'completely wrong', 'absolutely not', 'definitely false',\n            'never', 'utterly false', 'completely disagree'\n        ])\n        \n        negative = any(phrase in text_lower for phrase in [\n            'disagree', 'oppose', 'no', 'false', 'wrong', 'incorrect', 'dispute'\n        ])\n        \n        neutral = any(phrase in text_lower for phrase in [\n            'neutral', 'mixed', 'depends', 'complicated', 'unsure', 'both sides'\n        ])\n        \n        # Simulate reasoning\n        reasoning = {\n            'keyword_overlap': keyword_overlap,\n            'explicit_stance': None,\n            'confidence': 0.5,\n            'evidence_for': [],\n            'evidence_against': [],\n            'qualifications': []\n        }\n        \n        # Determine stance\n        if strong_positive:\n            reasoning['explicit_stance'] = 'strong_agree'\n            reasoning['confidence'] = 0.9\n            reasoning['score'] = 9\n        elif positive:\n            reasoning['explicit_stance'] = 'agree'\n            reasoning['confidence'] = 0.7\n            reasoning['score'] = 7\n        elif strong_negative:\n            reasoning['explicit_stance'] = 'strong_disagree'\n            reasoning['confidence'] = 0.9\n            reasoning['score'] = 1\n        elif negative:\n            reasoning['explicit_stance'] = 'disagree'\n            reasoning['confidence'] = 0.7\n            reasoning['score'] = 3\n        elif neutral:\n            reasoning['explicit_stance'] = 'neutral'\n            reasoning['confidence'] = 0.6\n            reasoning['score'] = 5\n        else:\n            # Use keyword overlap and context\n            if keyword_overlap > 0.5:\n                reasoning['score'] = 5 + int(keyword_overlap * 3)\n            else:\n                reasoning['score'] = 5  # Default neutral\n        \n        # Adjust based on keyword overlap\n        if reasoning.get('score'):\n            if keyword_overlap < 0.2:\n                reasoning['score'] = max(4, min(6, reasoning['score']))  # Force toward neutral\n        \n        return reasoning\n    \n    def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n        \"\"\"Measure belief using prompting-based approach.\"\"\"\n        if not proposition.strip() or not text.strip():\n            return 0.5, {'error': 'Empty proposition or text', 'method': 'prompting'}\n        \n        # Use multiple prompt templates for robust assessment\n        results = []\n        detailed_analysis = {}\n        \n        for template_name, template in self.prompt_templates.items():\n            prompt = template.format(proposition=proposition, text=text)\n            response = self._simulate_llm_response(prompt, proposition, text)\n            \n            if 'score' in response:\n                # Convert 0-10 scale to 0-1\n                normalized_score = response['score'] / 10.0\n                results.append(normalized_score)\n                detailed_analysis[template_name] = response\n        \n        # Ensemble the results\n        if results:\n            final_score = sum(results) / len(results)\n        else:\n            final_score = 0.5\n        \n        # Ensure score is in [0, 1]\n        final_score = max(0.0, min(1.0, final_score))\n        \n        breakdown = {\n            'final_score': final_score,\n            'method': 'prompting',\n            'individual_scores': results,\n            'detailed_analysis': detailed_analysis,\n            'num_prompts_used': len(results)\n        }\n        \n        return final_score, breakdown\n\n\nclass LogProbBasedStrategy(BeliefMeasurementStrategy):\n    \"\"\"\n    LogProb-based approach that estimates belief by comparing log probabilities\n    of agreement vs disagreement continuations.\n    \"\"\"\n    \n    def __init__(self):\n        # Simulated vocabulary with log probabilities\n        # In production, this would use actual model logprobs\n        self.vocab_logprobs = self._build_simulated_vocab()\n        \n        # Template continuations to test\n        self.agreement_templates = [\n            \"This statement is {token}\",\n            \"I {token} with this\",\n            \"This is {token}\",\n            \"The text {token} the proposition\"\n        ]\n        \n        self.agreement_tokens = ['true', 'correct', 'right', 'accurate', 'agree', 'support']\n        self.disagreement_tokens = ['false', 'wrong', 'incorrect', 'disagree', 'oppose', 'dispute']\n        self.neutral_tokens = ['unclear', 'mixed', 'neutral', 'uncertain']\n    \n    def _build_simulated_vocab(self) -> Dict[str, float]:\n        \"\"\"Build simulated vocabulary with log probabilities.\"\"\"\n        # Simulate log probabilities for common words\n        # In production, these would come from actual model\n        vocab = {\n            'true': -1.5, 'false': -1.8, 'correct': -2.1, 'wrong': -1.9,\n            'right': -1.7, 'incorrect': -2.3, 'accurate': -2.8,\n            'agree': -1.6, 'disagree': -2.0, 'support': -2.2, 'oppose': -2.5,\n            'dispute': -3.1, 'unclear': -2.7, 'mixed': -2.9, 'neutral': -2.4,\n            'uncertain': -2.8, 'definitely': -2.3, 'probably': -1.8,\n            'maybe': -2.1, 'never': -2.2, 'always': -2.4\n        }\n        return vocab\n    \n    def _calculate_context_logprob(self, context: str, token: str) -> float:\n        \"\"\"\n        Calculate log probability of token given context.\n        Simulates model behavior based on context analysis.\n        \"\"\"\n        base_logprob = self.vocab_logprobs.get(token, -4.0)  # Default for unknown tokens\n        \n        context_lower = context.lower()\n        \n        # Boost probability if context supports the token\n        if token in ['true', 'correct', 'right', 'accurate', 'agree', 'support']:\n            if any(phrase in context_lower for phrase in ['i think', 'believe', 'support', 'agree']):\n                base_logprob += 1.0\n            elif any(phrase in context_lower for phrase in ['disagree', 'oppose', 'wrong']):\n                base_logprob -= 1.5\n        \n        elif token in ['false', 'wrong', 'incorrect', 'disagree', 'oppose']:\n            if any(phrase in context_lower for phrase in ['disagree', 'oppose', 'wrong']):\n                base_logprob += 1.0\n            elif any(phrase in context_lower for phrase in ['agree', 'support', 'correct']):\n                base_logprob -= 1.5\n        \n        # Context relevance boost\n        prop_words = set(re.findall(r'\\b\\w+\\b', context_lower))\n        if token in prop_words:\n            base_logprob += 0.5\n        \n        return base_logprob\n    \n    def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n        \"\"\"Measure belief using log probability approach.\"\"\"\n        if not proposition.strip() or not text.strip():\n            return 0.5, {'error': 'Empty proposition or text', 'method': 'logprob'}\n        \n        # Create context by combining proposition and text\n        context = f\"Proposition: {proposition}\\nText: {text}\\n\"\n        \n        # Calculate log probabilities for different token types\n        agreement_logprobs = []\n        disagreement_logprobs = []\n        neutral_logprobs = []\n        \n        for template in self.agreement_templates:\n            for token in self.agreement_tokens:\n                filled_template = template.format(token=token)\n                full_context = context + filled_template\n                logprob = self._calculate_context_logprob(full_context, token)\n                agreement_logprobs.append(logprob)\n            \n            for token in self.disagreement_tokens:\n                filled_template = template.format(token=token)\n                full_context = context + filled_template\n                logprob = self._calculate_context_logprob(full_context, token)\n                disagreement_logprobs.append(logprob)\n            \n            for token in self.neutral_tokens:\n                filled_template = template.format(token=token)\n                full_context = context + filled_template\n                logprob = self._calculate_context_logprob(full_context, token)\n                neutral_logprobs.append(logprob)\n        \n        # Calculate average log probabilities\n        avg_agreement = sum(agreement_logprobs) / len(agreement_logprobs) if agreement_logprobs else -4.0\n        avg_disagreement = sum(disagreement_logprobs) / len(disagreement_logprobs) if disagreement_logprobs else -4.0\n        avg_neutral = sum(neutral_logprobs) / len(neutral_logprobs) if neutral_logprobs else -4.0\n        \n        # Convert to probabilities using softmax\n        logprobs = [avg_agreement, avg_disagreement, avg_neutral]\n        max_logprob = max(logprobs)\n        normalized_logprobs = [lp - max_logprob for lp in logprobs]\n        \n        exp_probs = [math.exp(lp) for lp in normalized_logprobs]\n        sum_exp = sum(exp_probs)\n        \n        prob_agreement = exp_probs[0] / sum_exp\n        prob_disagreement = exp_probs[1] / sum_exp\n        prob_neutral = exp_probs[2] / sum_exp\n        \n        # Convert to belief score (0 = disagree, 0.5 = neutral, 1 = agree)\n        belief_score = prob_agreement + 0.5 * prob_neutral\n        \n        breakdown = {\n            'final_score': belief_score,\n            'method': 'logprob',\n            'prob_agreement': prob_agreement,\n            'prob_disagreement': prob_disagreement,\n            'prob_neutral': prob_neutral,\n            'avg_agreement_logprob': avg_agreement,\n            'avg_disagreement_logprob': avg_disagreement,\n            'avg_neutral_logprob': avg_neutral,\n            'num_templates': len(self.agreement_templates)\n        }\n        \n        return belief_score, breakdown\n\nclass PatternBasedStrategy(BeliefMeasurementStrategy):\n    \"\"\"\n    Original pattern-based approach using regex patterns and rule-based analysis.\n    A pipeline to measure belief alignment between a proposition and free-form text.\n    Returns a score in [0,1] where 0=strongly disagrees, 0.5=neutral, 1=strongly agrees.\n    \"\"\"\n    \n    def __init__(self):\n        # Agreement indicators with weights\n        self.agreement_markers = {\n            'strong_agree': {\n                'patterns': [r'\\b(absolutely|completely|totally|entirely|fully)\\s+(agree|support|believe|endorse)',\n                           r'\\b(strongly|firmly)\\s+(agree|support|believe|endorse)',\n                           r'\\b(without\\s+doubt|undoubtedly|certainly|definitely)\\b.*\\b(true|correct|right)\\b',\n                           r'\\bI\\s+(completely|totally|absolutely|strongly)\\s+(agree|support|believe)\\b'],\n                'weight': 0.9\n            },\n            'agree': {\n                'patterns': [r'\\b(agree|support|believe|endorse|accept|embrace)\\b',\n                           r'\\b(yes|correct|true|right|accurate|valid)\\b',\n                           r'\\bI\\s+(think|believe|feel)\\s+.*\\b(true|correct|right)\\b'],\n                'weight': 0.7\n            },\n            'weak_agree': {\n                'patterns': [r'\\b(somewhat|partially|largely|mostly|generally)\\s+(agree|support|believe)',\n                           r'\\b(tend\\s+to|inclined\\s+to)\\s+(agree|believe|support)',\n                           r'\\b(probably|likely)\\s+(true|correct|right)\\b'],\n                'weight': 0.6\n            }\n        }\n        \n        # Disagreement indicators\n        self.disagreement_markers = {\n            'strong_disagree': {\n                'patterns': [r'\\b(absolutely|completely|totally|entirely|strongly)\\s+(disagree|oppose|reject)',\n                           r'\\b(never|not\\s+at\\s+all|in\\s+no\\s+way)\\b',\n                           r'\\b(completely|utterly|totally)\\s+(false|wrong|incorrect)',\n                           r'\\bI\\s+(completely|totally|absolutely|strongly)\\s+(disagree|oppose|reject)\\b'],\n                'weight': 0.1\n            },\n            'disagree': {\n                'patterns': [r'\\b(disagree|oppose|reject|deny|refute|dispute)\\b',\n                           r'\\b(no|false|wrong|incorrect|invalid|untrue)\\b',\n                           r'\\bI\\s+(don\\'?t|do\\s+not)\\s+(agree|believe|support|think)\\b'],\n                'weight': 0.3\n            },\n            'weak_disagree': {\n                'patterns': [r'\\b(somewhat|partially)\\s+(disagree|oppose)',\n                           r'\\b(doubt|question|skeptical|uncertain)\\b',\n                           r'\\b(probably|likely)\\s+(false|wrong|incorrect)\\b'],\n                'weight': 0.4\n            }\n        }\n        \n        # Neutral indicators\n        self.neutral_markers = {\n            'patterns': [r'\\b(neutral|undecided|unsure|uncertain|mixed\\s+feelings)\\b',\n                        r'\\b(both\\s+sides|on\\s+one\\s+hand.*on\\s+the\\s+other)\\b',\n                        r'\\b(depends|it\\'?s\\s+complicated|not\\s+sure)\\b'],\n                'weight': 0.5\n        }\n        \n    def handle_negations(self, text: str) -> Tuple[str, bool]:\n        \"\"\"Handle negations that might flip the meaning.\"\"\"\n        # Simple negation patterns\n        negation_patterns = [\n            (r'\\b(do\\s+not|don\\'t|does\\s+not|doesn\\'t|did\\s+not|didn\\'t)\\s+', ''),\n            (r'\\b(not|never|no)\\s+', ''),\n            (r'\\b(isn\\'t|aren\\'t|wasn\\'t|weren\\'t|won\\'t|wouldn\\'t|can\\'t|couldn\\'t)\\b', ''),\n        ]\n        \n        negation_count = 0\n        processed_text = text.lower()\n        \n        for pattern, replacement in negation_patterns:\n            matches = re.findall(pattern, processed_text, re.IGNORECASE)\n            negation_count += len(matches)\n            processed_text = re.sub(pattern, replacement, processed_text, flags=re.IGNORECASE)\n        \n        return processed_text, negation_count % 2 == 1  # Odd number of negations = flipped\n\n    def extract_agreement_signals(self, text: str, proposition: str) -> Dict[str, List[float]]:\n        \"\"\"Extract agreement/disagreement signals from text.\"\"\"\n        text_lower = text.lower()\n        prop_lower = proposition.lower()\n        \n        # Handle negations\n        processed_text, is_negated = self.handle_negations(text)\n        \n        # Combine text and proposition for context-aware matching\n        combined_text = f\"{prop_lower} {processed_text}\"\n        \n        signals = defaultdict(list)\n        \n        # Check agreement markers\n        for level, markers in self.agreement_markers.items():\n            for pattern in markers['patterns']:\n                matches = re.findall(pattern, combined_text, re.IGNORECASE)\n                if matches:\n                    weight = markers['weight']\n                    if is_negated:\n                        weight = 1.0 - weight  # Flip due to negation\n                    signals['agreement'].extend([weight] * len(matches))\n        \n        # Check disagreement markers\n        for level, markers in self.disagreement_markers.items():\n            for pattern in markers['patterns']:\n                matches = re.findall(pattern, combined_text, re.IGNORECASE)\n                if matches:\n                    weight = markers['weight']\n                    if is_negated:\n                        weight = 1.0 - weight  # Flip due to negation\n                    signals['disagreement'].extend([weight] * len(matches))\n        \n        # Check neutral markers\n        for pattern in self.neutral_markers['patterns']:\n            matches = re.findall(pattern, combined_text, re.IGNORECASE)\n            if matches:\n                signals['neutral'].extend([self.neutral_markers['weight']] * len(matches))\n        \n        return signals\n\n    def calculate_semantic_similarity(self, text: str, proposition: str) -> float:\n        \"\"\"\n        Simple semantic similarity based on word overlap and key terms.\n        In a production system, this would use embeddings.\n        \"\"\"\n        # Tokenize and clean\n        def tokenize(s):\n            return set(re.findall(r'\\b\\w+\\b', s.lower()))\n        \n        text_tokens = tokenize(text)\n        prop_tokens = tokenize(proposition)\n        \n        if not prop_tokens:\n            return 0.5\n        \n        # Calculate overlap\n        intersection = text_tokens.intersection(prop_tokens)\n        union = text_tokens.union(prop_tokens)\n        \n        if not union:\n            return 0.5\n        \n        jaccard_similarity = len(intersection) / len(union)\n        \n        # Boost for exact proposition mentions\n        prop_words = proposition.lower().split()\n        text_lower = text.lower()\n        \n        exact_mentions = sum(1 for word in prop_words if word in text_lower)\n        mention_boost = min(exact_mentions / len(prop_words), 0.3)\n        \n        return min(jaccard_similarity + mention_boost, 1.0)\n    \n    def analyze_context_sentiment(self, text: str, proposition: str) -> float:\n        \"\"\"\n        Analyze sentiment in context of the proposition.\n        Simple implementation - in production would use proper sentiment analysis.\n        \"\"\"\n        text_lower = text.lower()\n        \n        # Positive sentiment words\n        positive_words = ['good', 'great', 'excellent', 'wonderful', 'amazing', 'fantastic',\n                         'beneficial', 'helpful', 'valuable', 'important', 'necessary',\n                         'essential', 'vital', 'crucial', 'significant']\n        \n        # Negative sentiment words\n        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'wrong', 'harmful',\n                         'dangerous', 'problematic', 'concerning', 'worrying', 'alarming',\n                         'unnecessary', 'useless', 'pointless', 'wasteful']\n        \n        positive_count = sum(1 for word in positive_words if word in text_lower)\n        negative_count = sum(1 for word in negative_words if word in text_lower)\n        \n        if positive_count == 0 and negative_count == 0:\n            return 0.5\n        \n        total = positive_count + negative_count\n        return positive_count / total\n    \n    def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n        \"\"\"\n        Main method to measure belief alignment.\n        Returns belief score and detailed breakdown.\n        \"\"\"\n        if not proposition.strip() or not text.strip():\n            return 0.5, {'error': 'Empty proposition or text', 'method': 'pattern'}\n        \n        # Extract signals\n        signals = self.extract_agreement_signals(text, proposition)\n        \n        # Calculate components\n        semantic_sim = self.calculate_semantic_similarity(text, proposition)\n        context_sentiment = self.analyze_context_sentiment(text, proposition)\n        \n        # Aggregate agreement/disagreement signals\n        agreement_scores = signals.get('agreement', [])\n        disagreement_scores = signals.get('disagreement', [])\n        neutral_scores = signals.get('neutral', [])\n        \n        # Calculate weighted averages\n        if agreement_scores:\n            avg_agreement = sum(agreement_scores) / len(agreement_scores)\n        else:\n            avg_agreement = None\n            \n        if disagreement_scores:\n            avg_disagreement = sum(disagreement_scores) / len(disagreement_scores)\n        else:\n            avg_disagreement = None\n        \n        # Combine signals with weights\n        components = []\n        weights = []\n        \n        # Primary signals (explicit agreement/disagreement)\n        if avg_agreement is not None:\n            components.append(avg_agreement)\n            weights.append(0.5)  # High weight for explicit agreement\n        \n        if avg_disagreement is not None:\n            components.append(avg_disagreement)\n            weights.append(0.5)  # High weight for explicit disagreement\n        \n        # Secondary signals\n        if semantic_sim > 0:\n            components.append(0.5 + (semantic_sim - 0.5) * 0.3)  # Moderate influence\n            weights.append(0.2)\n        \n        if context_sentiment != 0.5:\n            components.append(context_sentiment)\n            weights.append(0.2)\n        \n        # Handle neutral signals\n        if neutral_scores:\n            components.append(0.5)\n            weights.append(0.3)\n        \n        # Default to neutral if no signals\n        if not components:\n            final_score = 0.5\n        else:\n            # Weighted average\n            final_score = sum(c * w for c, w in zip(components, weights)) / sum(weights)\n        \n        # Ensure score is in [0, 1]\n        final_score = max(0.0, min(1.0, final_score))\n        \n        # Prepare detailed breakdown\n        breakdown = {\n            'final_score': final_score,\n            'method': 'pattern',\n            'semantic_similarity': semantic_sim,\n            'context_sentiment': context_sentiment,\n            'agreement_signals': len(agreement_scores),\n            'disagreement_signals': len(disagreement_scores),\n            'neutral_signals': len(neutral_scores),\n            'avg_agreement': avg_agreement,\n            'avg_disagreement': avg_disagreement,\n            'components_used': len(components)\n        }\n        \n        return final_score, breakdown\n\n\nclass BeliefMeasurementPipeline:\n    \"\"\"\n    Unified pipeline supporting multiple belief measurement strategies:\n    - Pattern-based (regex + rules)\n    - Prompting-based (structured prompts)  \n    - LogProb-based (probability comparison)\n    - Ensemble (combination of multiple strategies)\n    \"\"\"\n    \n    def __init__(self, strategy: str = 'ensemble'):\n        \"\"\"\n        Initialize pipeline with specified strategy.\n        \n        Args:\n            strategy: 'pattern', 'prompting', 'logprob', or 'ensemble'\n        \"\"\"\n        self.strategies = {\n            'pattern': PatternBasedStrategy(),\n            'prompting': PromptingBasedStrategy(), \n            'logprob': LogProbBasedStrategy()\n        }\n        \n        self.strategy_name = strategy\n        if strategy == 'ensemble':\n            self.active_strategies = list(self.strategies.values())\n        else:\n            self.active_strategies = [self.strategies[strategy]]\n    \n    def measure_belief(self, proposition: str, text: str) -> Tuple[float, Dict]:\n        \"\"\"\n        Measure belief using the configured strategy/strategies.\n        \"\"\"\n        if not proposition.strip() or not text.strip():\n            return 0.5, {'error': 'Empty proposition or text'}\n        \n        if self.strategy_name == 'ensemble':\n            return self._ensemble_measure(proposition, text)\n        else:\n            return self.active_strategies[0].measure_belief(proposition, text)\n    \n    def _ensemble_measure(self, proposition: str, text: str) -> Tuple[float, Dict]:\n        \"\"\"Combine multiple strategies using ensemble approach.\"\"\"\n        results = []\n        detailed_results = {}\n        \n        # Get results from each strategy\n        for name, strategy in self.strategies.items():\n            try:\n                score, breakdown = strategy.measure_belief(proposition, text)\n                results.append(score)\n                detailed_results[name] = {\n                    'score': score,\n                    'breakdown': breakdown\n                }\n            except Exception as e:\n                detailed_results[name] = {\n                    'error': str(e)\n                }\n        \n        if not results:\n            return 0.5, {'error': 'All strategies failed'}\n        \n        # Weighted ensemble (can be adjusted based on strategy reliability)\n        weights = {\n            'pattern': 0.4,    # Good for explicit statements\n            'prompting': 0.4,  # Good for nuanced reasoning\n            'logprob': 0.2     # Good for implicit signals\n        }\n        \n        weighted_score = 0\n        total_weight = 0\n        \n        for i, (name, strategy) in enumerate(self.strategies.items()):\n            if name in detailed_results and 'score' in detailed_results[name]:\n                weight = weights.get(name, 1.0 / len(self.strategies))\n                weighted_score += detailed_results[name]['score'] * weight\n                total_weight += weight\n        \n        final_score = weighted_score / total_weight if total_weight > 0 else 0.5\n        \n        # Calculate agreement between strategies (confidence measure)\n        if len(results) > 1:\n            mean_score = sum(results) / len(results)\n            variance = sum((s - mean_score) ** 2 for s in results) / len(results)\n            agreement = 1.0 - min(variance * 4, 1.0)  # Higher agreement = lower variance\n        else:\n            agreement = 1.0\n        \n        breakdown = {\n            'final_score': final_score,\n            'method': 'ensemble',\n            'strategy_results': detailed_results,\n            'individual_scores': results,\n            'agreement_score': agreement,\n            'weights_used': weights\n        }\n        \n        return final_score, breakdown\n\n\ndef main():\n    \"\"\"Main function to run the belief measurement pipeline.\"\"\"\n    print(\"🚀 Belief Measurement Pipeline\")\n    print(\"=\" * 50)\n    \n    # Test cases\n    test_cases = [\n        {\n            'name': 'Strong Agreement',\n            'proposition': 'Climate change is a serious threat',\n            'text': 'I absolutely agree that climate change poses a significant danger to our planet and requires immediate action.',\n            'expected_range': (0.8, 1.0)\n        },\n        {\n            'name': 'Strong Disagreement', \n            'proposition': 'Vaccines are dangerous',\n            'text': 'I completely disagree. Vaccines are safe, effective, and this claim is utterly false according to scientific evidence.',\n            'expected_range': (0.0, 0.2)\n        },\n        {\n            'name': 'Qualified Agreement',\n            'proposition': 'Remote work increases productivity',\n            'text': 'I think remote work can increase productivity for some people, but it depends on the individual and the type of work.',\n            'expected_range': (0.5, 0.8)\n        },\n        {\n            'name': 'Neutral/Irrelevant',\n            'proposition': 'Pizza is the best food',\n            'text': 'I went to the store yesterday and bought some groceries. The weather was nice and I saw a dog.',\n            'expected_range': (0.4, 0.6)\n        },\n        {\n            'name': 'Subtle Disagreement',\n            'proposition': 'Social media improves mental health',\n            'text': 'While social media connects people, research suggests it might actually increase anxiety and depression rather than helping.',\n            'expected_range': (0.2, 0.5)\n        }\n    ]\n    \n    strategies = ['pattern', 'prompting', 'logprob', 'ensemble']\n    \n    print(\"📊 Running Comprehensive Tests\")\n    print(\"=\" * 50)\n    \n    for case in test_cases:\n        print(f\"\\n✨ Test Case: {case['name']}\")\n        print(f\"📝 Proposition: {case['proposition']}\")\n        print(f\"💬 Text: {case['text']}\")\n        print(f\"🎯 Expected Range: {case['expected_range']}\")\n        print(\"-\" * 40)\n        \n        for strategy in strategies:\n            pipeline = BeliefMeasurementPipeline(strategy=strategy)\n            score, breakdown = pipeline.measure_belief(case['proposition'], case['text'])\n            \n            in_range = case['expected_range'][0] <= score <= case['expected_range'][1]\n            status = \"✅ PASS\" if in_range else \"⚠️ REVIEW\"\n            \n            print(f\"{strategy:>12}: {score:.3f} {status}\")\n            \n            # Show detailed breakdown for ensemble\n            if strategy == 'ensemble' and 'strategy_results' in breakdown:\n                individual_scores = []\n                for strat_name, result in breakdown['strategy_results'].items():\n                    if 'score' in result:\n                        individual_scores.append(f\"{strat_name}: {result['score']:.3f}\")\n                print(f\"{'':>12}  └─ {', '.join(individual_scores)}\")\n                print(f\"{'':>12}  └─ Agreement: {breakdown.get('agreement_score', 0):.3f}\")\n        \n        print()\n\n    # Interactive Demo\n    print(\"\\n🎮 Interactive Demo\")\n    print(\"=\" * 30)\n    \n    demo_cases = [\n        {\n            'proposition': 'Artificial intelligence will benefit humanity',\n            'text': 'AI has tremendous potential to solve complex problems in healthcare, climate change, and education. While there are risks to manage, the benefits far outweigh the concerns when developed responsibly.'\n        },\n        {\n            'proposition': 'Working from home is more productive',\n            'text': 'I completely disagree with remote work being more productive. In my experience, office collaboration and direct supervision lead to much better results.'\n        }\n    ]\n    \n    pipeline = BeliefMeasurementPipeline('ensemble')\n    \n    for i, demo in enumerate(demo_cases, 1):\n        print(f\"\\n📋 Demo {i}:\")\n        print(f\"Proposition: {demo['proposition']}\")\n        print(f\"Text: {demo['text']}\")\n        \n        score, breakdown = pipeline.measure_belief(demo['proposition'], demo['text'])\n        \n        # Interpret the score\n        if score >= 0.8:\n            interpretation = \"🔥 Strong Agreement\"\n        elif score >= 0.6:\n            interpretation = \"✅ Agreement\"\n        elif score >= 0.4:\n            interpretation = \"🤔 Neutral/Mixed\"\n        elif score >= 0.2:\n            interpretation = \"❌ Disagreement\"\n        else:\n            interpretation = \"🚫 Strong Disagreement\"\n        \n        print(f\"\\n📊 Final Score: {score:.3f}\")\n        print(f\"🎯 Interpretation: {interpretation}\")\n        \n        print(\"🔍 Strategy Breakdown:\")\n        for strategy_name, result in breakdown.get('strategy_results', {}).items():\n            if 'score' in result:\n                print(f\"  • {strategy_name.capitalize()}: {result['score']:.3f}\")\n        \n        print(f\"  • Strategy Agreement: {breakdown.get('agreement_score', 0):.3f}\")\n        print(\"-\" * 30)\n\n    print(\"\\n✨ Pipeline execution completed!\")\n    print(\"💡 Use this code to analyze belief alignment in your own text data.\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T01:38:52.575610Z","iopub.execute_input":"2025-07-20T01:38:52.576119Z","iopub.status.idle":"2025-07-20T01:38:52.645165Z","shell.execute_reply.started":"2025-07-20T01:38:52.576092Z","shell.execute_reply":"2025-07-20T01:38:52.644240Z"}},"outputs":[{"name":"stdout","text":"🚀 Belief Measurement Pipeline\n==================================================\n📊 Running Comprehensive Tests\n==================================================\n\n✨ Test Case: Strong Agreement\n📝 Proposition: Climate change is a serious threat\n💬 Text: I absolutely agree that climate change poses a significant danger to our planet and requires immediate action.\n🎯 Expected Range: (0.8, 1.0)\n----------------------------------------\n     pattern: 0.793 ⚠️ REVIEW\n   prompting: 0.900 ✅ PASS\n     logprob: 0.748 ⚠️ REVIEW\n    ensemble: 0.827 ✅ PASS\n              └─ pattern: 0.793, prompting: 0.900, logprob: 0.748\n              └─ Agreement: 0.984\n\n\n✨ Test Case: Strong Disagreement\n📝 Proposition: Vaccines are dangerous\n💬 Text: I completely disagree. Vaccines are safe, effective, and this claim is utterly false according to scientific evidence.\n🎯 Expected Range: (0.0, 0.2)\n----------------------------------------\n     pattern: 0.264 ⚠️ REVIEW\n   prompting: 0.700 ⚠️ REVIEW\n     logprob: 0.600 ⚠️ REVIEW\n    ensemble: 0.505 ⚠️ REVIEW\n              └─ pattern: 0.264, prompting: 0.700, logprob: 0.600\n              └─ Agreement: 0.861\n\n\n✨ Test Case: Qualified Agreement\n📝 Proposition: Remote work increases productivity\n💬 Text: I think remote work can increase productivity for some people, but it depends on the individual and the type of work.\n🎯 Expected Range: (0.5, 0.8)\n----------------------------------------\n     pattern: 0.494 ⚠️ REVIEW\n   prompting: 0.500 ✅ PASS\n     logprob: 0.710 ✅ PASS\n    ensemble: 0.540 ✅ PASS\n              └─ pattern: 0.494, prompting: 0.500, logprob: 0.710\n              └─ Agreement: 0.960\n\n\n✨ Test Case: Neutral/Irrelevant\n📝 Proposition: Pizza is the best food\n💬 Text: I went to the store yesterday and bought some groceries. The weather was nice and I saw a dog.\n🎯 Expected Range: (0.4, 0.6)\n----------------------------------------\n     pattern: 0.425 ✅ PASS\n   prompting: 0.700 ⚠️ REVIEW\n     logprob: 0.575 ✅ PASS\n    ensemble: 0.565 ✅ PASS\n              └─ pattern: 0.425, prompting: 0.700, logprob: 0.575\n              └─ Agreement: 0.949\n\n\n✨ Test Case: Subtle Disagreement\n📝 Proposition: Social media improves mental health\n💬 Text: While social media connects people, research suggests it might actually increase anxiety and depression rather than helping.\n🎯 Expected Range: (0.2, 0.5)\n----------------------------------------\n     pattern: 0.470 ✅ PASS\n   prompting: 0.500 ✅ PASS\n     logprob: 0.575 ⚠️ REVIEW\n    ensemble: 0.503 ⚠️ REVIEW\n              └─ pattern: 0.470, prompting: 0.500, logprob: 0.575\n              └─ Agreement: 0.992\n\n\n🎮 Interactive Demo\n==============================\n\n📋 Demo 1:\nProposition: Artificial intelligence will benefit humanity\nText: AI has tremendous potential to solve complex problems in healthcare, climate change, and education. While there are risks to manage, the benefits far outweigh the concerns when developed responsibly.\n\n📊 Final Score: 0.479\n🎯 Interpretation: 🤔 Neutral/Mixed\n🔍 Strategy Breakdown:\n  • Pattern: 0.410\n  • Prompting: 0.500\n  • Logprob: 0.575\n  • Strategy Agreement: 0.982\n------------------------------\n\n📋 Demo 2:\nProposition: Working from home is more productive\nText: I completely disagree with remote work being more productive. In my experience, office collaboration and direct supervision lead to much better results.\n\n📊 Final Score: 0.500\n🎯 Interpretation: 🤔 Neutral/Mixed\n🔍 Strategy Breakdown:\n  • Pattern: 0.251\n  • Prompting: 0.700\n  • Logprob: 0.600\n  • Strategy Agreement: 0.852\n------------------------------\n\n✨ Pipeline execution completed!\n💡 Use this code to analyze belief alignment in your own text data.\n","output_type":"stream"}],"execution_count":5}]}